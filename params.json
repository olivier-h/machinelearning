{"name":"Coursera Machine Learning Project Assignment","tagline":"Coursera Project Assignment","body":"# Predicting exercice quality through accelerometers data\r\n\r\n## Introduction\r\n\r\nIn this project we will analyse the accelerometers measurements on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways.\r\nWe will try to fit a model to predict activity from measurements, using cross validation on a training dataset.\r\nThen, calculating the out of sample error comparing real and predicted activity will give us the model accuracy.\r\n\r\n## Exploratory data analysis\r\n\r\nThe training dataset is loaded from the \"pml-training.csv\" file.\r\n\r\n\r\n```r\r\n# Cleaning the environment\r\nrm(list = ls(all = TRUE))\r\n\r\n# Setting the working directory\r\nsetwd(\"E:\\\\BIG DATA\\\\Coursera - Data Scientist\\\\08 - Practical Machine Learning\\\\PA\")\r\n\r\n# Initialising the data file name containing the data (it must be in the working directory)\r\ntrainingFileName = \"pml-training.csv\"\r\n\r\n# Reading the data and putting it in a dataframe\r\ntrainingdataset = read.csv(trainingFileName, header = TRUE, sep = \",\", stringsAsFactors = FALSE)\r\n```\r\n\r\nThis dataset has to be cleaned. Indeed, the first 8 columns are metadata, they are not needed in the model.\r\nMoreover, a few measurements have only NA values or only empty values.\r\n\r\n\r\n```r\r\n# Function to calculate data percentage in each column\r\ncountPercentData = function(v) {\r\n\tcount = 0\r\n\tfor (i in 1:length(v)) {\r\n\t\tif (is.na(v[i]) | v[i] == \"\") {\r\n\t\t\tcount = count + 1\r\n\t\t}\r\n\t}\r\n\t100 - count / length(v) *100\r\n}\r\n\r\n# Getting data percentage in each column\r\ndataPercentColumn = apply(trainingdataset, 2, function(v) countPercentData(v))\r\n\r\n# Removing colmns with less than 100% data and with metadata\r\ncolumnNames = names((dataPercentColumn[dataPercentColumn == 100]))\r\ncolumnNames = columnNames[8:length(columnNames)]\r\n```\r\n\r\nWe will only conserve columns with all values filled.\r\n\r\n\r\n```r\r\n# Selecting columns in the training dataset\r\ntrainingdataset = trainingdataset[, columnNames]\r\n\r\n# Setting the outcome as a factor\r\ntrainingdataset$classe = factor(trainingdataset$classe)\r\n```\r\n\r\n## Model analysis\r\n\r\nWe will use the caret package to perform cross validation. From the training dataset, we will create training (60%) and testing (40%) partitions.\r\n\r\n\r\n```r\r\n# Loading the needed libraries\r\nlibrary(caret)\r\nlibrary(randomForest)\r\n\r\n# Creating training and testing partitions (cross validation)\r\ninTrain = createDataPartition(y = trainingdataset$classe, p = 0.6, list = FALSE)\r\ntraining = trainingdataset[inTrain, ]\r\ntesting  = trainingdataset[-inTrain, ]\r\n```\r\n\r\nWe will use the training partition to fit a random forest model with the \"classe\" variable as outcome and all other variables as predictors.\r\n\r\n\r\n```r\r\n# Fitting a random forest model on the training partition\r\nmodFit = randomForest(classe ~ ., data = training)\r\n```\r\n\r\nWe will predict the outcome with the model on the testing partition.\r\n\r\n\r\n```r\r\n# Applying the model on the testing partition\r\npredictions = predict(modFit, testing)\r\n```\r\n\r\nPrinting a confusion matrix between real and predicted data will give us out of sample error.\r\n\r\n\r\n```r\r\n# Estimating the model accuracy comparing real and predicted data\r\nconfusionMatrix(predictions, testing$classe)\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 2231    8    0    0    0\r\n##          B    1 1505   23    0    0\r\n##          C    0    5 1345   10    0\r\n##          D    0    0    0 1276   14\r\n##          E    0    0    0    0 1428\r\n## \r\n## Overall Statistics\r\n##                                        \r\n##                Accuracy : 0.9922       \r\n##                  95% CI : (0.99, 0.994)\r\n##     No Information Rate : 0.2845       \r\n##     P-Value [Acc > NIR] : < 2.2e-16    \r\n##                                        \r\n##                   Kappa : 0.9902       \r\n##  Mcnemar's Test P-Value : NA           \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9996   0.9914   0.9832   0.9922   0.9903\r\n## Specificity            0.9986   0.9962   0.9977   0.9979   1.0000\r\n## Pos Pred Value         0.9964   0.9843   0.9890   0.9891   1.0000\r\n## Neg Pred Value         0.9998   0.9979   0.9965   0.9985   0.9978\r\n## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2843   0.1918   0.1714   0.1626   0.1820\r\n## Detection Prevalence   0.2854   0.1949   0.1733   0.1644   0.1820\r\n## Balanced Accuracy      0.9991   0.9938   0.9904   0.9950   0.9951\r\n```\r\n\r\n## Conclusion\r\nA random forest model is particularly accurate on this case (> 99%).\r\nWe can conclude that activity quality can be accurately predicted from accelerometers measurements.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}